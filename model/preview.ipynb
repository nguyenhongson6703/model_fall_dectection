{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e580f893-eade-4bad-ac6e-fd5fb68355c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:43.655359Z",
     "iopub.status.busy": "2024-03-17T06:40:43.655359Z",
     "iopub.status.idle": "2024-03-17T06:40:47.132516Z",
     "shell.execute_reply": "2024-03-17T06:40:47.132516Z",
     "shell.execute_reply.started": "2024-03-17T06:40:43.655359Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import threading\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e411f9fd-5019-4adf-9cd4-fda9a656c749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:53.812271Z",
     "iopub.status.busy": "2024-03-17T06:40:53.811144Z",
     "iopub.status.idle": "2024-03-17T06:40:55.235030Z",
     "shell.execute_reply": "2024-03-17T06:40:55.235030Z",
     "shell.execute_reply.started": "2024-03-17T06:40:53.812271Z"
    }
   },
   "outputs": [],
   "source": [
    "n_time_steps = 5\n",
    "model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60cb42d2-27d4-4a91-a6d9-b4e868a5cac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:55.236003Z",
     "iopub.status.busy": "2024-03-17T06:40:55.236003Z",
     "iopub.status.idle": "2024-03-17T06:40:55.239280Z",
     "shell.execute_reply": "2024-03-17T06:40:55.239280Z",
     "shell.execute_reply.started": "2024-03-17T06:40:55.236003Z"
    }
   },
   "outputs": [],
   "source": [
    "mediapipe_pose_model_asset = \"mediapipe_pose_landmarker_model/pose_landmarker_heavy.task\"\n",
    "#mediapipe_pose_model_asset = \"mediapipe_pose_landmarker_model/pose_landmarker_full.task\"\n",
    "base_options = python.BaseOptions(model_asset_path=mediapipe_pose_model_asset)\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        running_mode=vision.RunningMode.VIDEO,\n",
    "        num_poses=1,\n",
    "        min_pose_detection_confidence=0.5,\n",
    "        min_pose_presence_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        output_segmentation_masks=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c737860-e776-4fc1-a365-164ba6bdeea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0913ec5e-fe1c-4c13-a1a1-b4ad3e2bdb7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:56.241103Z",
     "iopub.status.busy": "2024-03-17T06:40:56.240110Z",
     "iopub.status.idle": "2024-03-17T06:40:56.246319Z",
     "shell.execute_reply": "2024-03-17T06:40:56.246319Z",
     "shell.execute_reply.started": "2024-03-17T06:40:56.241103Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_landmark_timestep(results):\n",
    "    c_lm = []\n",
    "    def add_lanmark(index):\n",
    "        landmark = results.pose_landmarks[0][index]\n",
    "        c_lm.append(landmark.x)\n",
    "        c_lm.append(landmark.y)\n",
    "        c_lm.append(landmark.z)\n",
    "        c_lm.append(landmark.visibility)\n",
    "        \n",
    "    add_lanmark(0)\n",
    "    add_lanmark(11)\n",
    "    add_lanmark(12)\n",
    "    add_lanmark(13)\n",
    "    add_lanmark(14)\n",
    "    add_lanmark(15)\n",
    "    add_lanmark(16)\n",
    "    add_lanmark(23)\n",
    "    add_lanmark(24)\n",
    "    add_lanmark(25)\n",
    "    add_lanmark(26)\n",
    "    add_lanmark(27)\n",
    "    add_lanmark(28)\n",
    "\n",
    "    return c_lm\n",
    "\n",
    "\n",
    "def draw_landmark_on_image(mpDraw, results, img):\n",
    "    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)\n",
    "    for id, lm in enumerate(results.pose_landmarks.landmark):\n",
    "        h, w, c = img.shape\n",
    "        print(id, lm)\n",
    "        cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "    return img\n",
    "\n",
    "\n",
    "def draw_class_on_image(label, img):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    bottomLeftCornerOfText = (10, 30)\n",
    "    fontScale = 1\n",
    "    fontColor = (0, 255, 0)\n",
    "    thickness = 2\n",
    "    lineType = 2\n",
    "    cv2.putText(img, label,\n",
    "                bottomLeftCornerOfText,\n",
    "                font,\n",
    "                fontScale,\n",
    "                fontColor,\n",
    "                thickness,\n",
    "                lineType)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a92c2fde-6f0d-47ab-a2b4-81d286b40b76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:57.655209Z",
     "iopub.status.busy": "2024-03-17T06:40:57.655209Z",
     "iopub.status.idle": "2024-03-17T06:40:57.660107Z",
     "shell.execute_reply": "2024-03-17T06:40:57.660107Z",
     "shell.execute_reply.started": "2024-03-17T06:40:57.655209Z"
    }
   },
   "outputs": [],
   "source": [
    "def detect(model, lm_list):\n",
    "    global label\n",
    "    lm_list = np.array(lm_list)\n",
    "    lm_list = np.expand_dims(lm_list, axis=0)\n",
    "    #print(lm_list.shape)\n",
    "    results = model.predict(lm_list)\n",
    "    #print(results)\n",
    "    if results[0][0] > 0.5:\n",
    "        label = \"FALLING\"\n",
    "    else:\n",
    "        label = \"NOT FALL\"\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3e4ea1-abc3-4b5f-aa29-67f1ebd55afb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:40:58.622302Z",
     "iopub.status.busy": "2024-03-17T06:40:58.622302Z",
     "iopub.status.idle": "2024-03-17T06:40:58.627168Z",
     "shell.execute_reply": "2024-03-17T06:40:58.627168Z",
     "shell.execute_reply.started": "2024-03-17T06:40:58.622302Z"
    }
   },
   "outputs": [],
   "source": [
    "executor = ThreadPoolExecutor(max_workers=1)\n",
    "\n",
    "def threaded_detect(model, lm_data):\n",
    "    global label\n",
    "    label = detect(model, lm_data)\n",
    "    # Consider adding any post-detection logic here, if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b5de27f-5e25-4eef-8e4e-2b56c5da80eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-17T06:46:55.499114Z",
     "iopub.status.busy": "2024-03-17T06:46:55.499114Z",
     "iopub.status.idle": "2024-03-17T06:47:40.833794Z",
     "shell.execute_reply": "2024-03-17T06:47:40.832821Z",
     "shell.execute_reply.started": "2024-03-17T06:46:55.499114Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input timestamp must be monotonically increasing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m mp_image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage(image_format\u001b[38;5;241m=\u001b[39mmp\u001b[38;5;241m.\u001b[39mImageFormat\u001b[38;5;241m.\u001b[39mSRGB, data\u001b[38;5;241m=\u001b[39mrgb_image)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# tren rpi, toc do toi da 5 fps\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect_for_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmp_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_MSEC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m current_frame \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m    \n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mpose_landmarks:\n",
      "File \u001b[1;32mc:\\users\\caokh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\pose_landmarker.py:395\u001b[0m, in \u001b[0;36mPoseLandmarker.detect_for_video\u001b[1;34m(self, image, timestamp_ms, image_processing_options)\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs pose landmarks detection on the provided video frame.\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \n\u001b[0;32m    372\u001b[0m \u001b[38;5;124;03mOnly use this method when the PoseLandmarker is created with the video\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m  RuntimeError: If pose landmarker detection failed to run.\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    392\u001b[0m normalized_rect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_normalized_rect(\n\u001b[0;32m    393\u001b[0m     image_processing_options, image, roi_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    394\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m output_packets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_video_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_IMAGE_IN_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_MICRO_SECONDS_PER_MILLISECOND\u001b[49m\n\u001b[0;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_NORM_RECT_STREAM_NAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_proto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalized_rect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pb2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimestamp_ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_MICRO_SECONDS_PER_MILLISECOND\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_packets[_NORM_LANDMARKS_STREAM_NAME]\u001b[38;5;241m.\u001b[39mis_empty():\n\u001b[0;32m    405\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m PoseLandmarkerResult([], [])\n",
      "File \u001b[1;32mc:\\users\\caokh\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\core\\base_vision_task_api.py:119\u001b[0m, in \u001b[0;36mBaseVisionTaskApi._process_video_data\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode \u001b[38;5;241m!=\u001b[39m _RunningMode\u001b[38;5;241m.\u001b[39mVIDEO:\n\u001b[0;32m    115\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTask is not initialized with the video mode. Current running mode:\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode\u001b[38;5;241m.\u001b[39mname\n\u001b[0;32m    118\u001b[0m   )\n\u001b[1;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Input timestamp must be monotonically increasing."
     ]
    }
   ],
   "source": [
    "file_name = \"evaluation/test_nofall.mp4\"\n",
    "video = cv2.VideoCapture(file_name)\n",
    "detector = vision.PoseLandmarker.create_from_options(options)\n",
    "lm_list = []\n",
    "label = \"Please wait\"\n",
    "current_frame = 0\n",
    "while True:\n",
    "    success, frame = video.read()\n",
    "    \n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "    \n",
    "    # tren rpi, toc do toi da 5 fps\n",
    "    results = detector.detect_for_video(mp_image, int(video.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "    current_frame += 1    \n",
    "    if results.pose_landmarks:\n",
    "        if current_frame % 6 == 0: # moi truong video, cu 6 frame thi lay keypoint day vao model, \n",
    "                                    # tren rpi k can phai check frame, day thang vao (vi co delay san)\n",
    "            c_lm = make_landmark_timestep(results)\n",
    "            lm_list.append(c_lm)\n",
    "            if len(lm_list) >= n_time_steps:\n",
    "                lm_data_to_predict = lm_list[-n_time_steps:]\n",
    "                executor.submit(threaded_detect, model, lm_data_to_predict)\n",
    "                lm_list.pop(0)\n",
    "                #lm_list = []\n",
    "           \n",
    "        for pose_landmarks in results.pose_landmarks:\n",
    "                # Draw the pose landmarks.\n",
    "                pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "                pose_landmarks_proto.landmark.extend([\n",
    "                    landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y,\n",
    "                                                    z=landmark.z) for landmark\n",
    "                    in pose_landmarks\n",
    "                ])\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame,\n",
    "                    pose_landmarks_proto,\n",
    "                    mp_pose.POSE_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    else:\n",
    "        lm_list = []\n",
    "        \n",
    "    frame = draw_class_on_image(label, frame)\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f3ace8-60a2-45c6-99a2-a111964580a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
