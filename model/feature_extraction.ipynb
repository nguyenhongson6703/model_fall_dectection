{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "991acaf7-34d1-447f-95de-85b5d684b6d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:49:53.804641Z",
     "iopub.status.busy": "2024-06-10T15:49:53.804641Z",
     "iopub.status.idle": "2024-06-10T15:49:53.809539Z",
     "shell.execute_reply": "2024-06-10T15:49:53.809539Z",
     "shell.execute_reply.started": "2024-06-10T15:49:53.804641Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import csv\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f999f28c-f48e-4679-8013-591167d7bdc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:49:59.901565Z",
     "iopub.status.busy": "2024-06-10T15:49:59.900589Z",
     "iopub.status.idle": "2024-06-10T15:49:59.905470Z",
     "shell.execute_reply": "2024-06-10T15:49:59.905470Z",
     "shell.execute_reply.started": "2024-06-10T15:49:59.901565Z"
    }
   },
   "outputs": [],
   "source": [
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00155fc0-9e1d-4b77-9194-3c4827d7ac71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:00.127521Z",
     "iopub.status.busy": "2024-06-10T15:50:00.126544Z",
     "iopub.status.idle": "2024-06-10T15:50:00.301696Z",
     "shell.execute_reply": "2024-06-10T15:50:00.301696Z",
     "shell.execute_reply.started": "2024-06-10T15:50:00.127521Z"
    }
   },
   "outputs": [],
   "source": [
    "model = \"mediapipe_pose_landmarker_model/pose_landmarker_heavy.task\"\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=model)\n",
    "options = vision.PoseLandmarkerOptions(\n",
    "        base_options=base_options,\n",
    "        running_mode=vision.RunningMode.VIDEO,\n",
    "        num_poses=1,\n",
    "        min_pose_detection_confidence=0.5,\n",
    "        min_pose_presence_confidence=0.5,\n",
    "        min_tracking_confidence=0.5,\n",
    "        output_segmentation_masks=False)\n",
    "\n",
    "detector = vision.PoseLandmarker.create_from_options(options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45cf2851-a3f9-494d-af05-9d8f34f3dadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:00.313445Z",
     "iopub.status.busy": "2024-06-10T15:50:00.313445Z",
     "iopub.status.idle": "2024-06-10T15:50:00.318358Z",
     "shell.execute_reply": "2024-06-10T15:50:00.318358Z",
     "shell.execute_reply.started": "2024-06-10T15:50:00.313445Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_total_frames(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file {video_path}\")\n",
    "        return 0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "659eb77e-378d-4ee6-8b45-2e6cd4561e7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:00.497357Z",
     "iopub.status.busy": "2024-06-10T15:50:00.496379Z",
     "iopub.status.idle": "2024-06-10T15:50:00.504227Z",
     "shell.execute_reply": "2024-06-10T15:50:00.503251Z",
     "shell.execute_reply.started": "2024-06-10T15:50:00.497357Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_csv_file(filename):\n",
    "    csvfile_handler = open(filename, 'w', newline='')\n",
    "    landmark_writer = csv.writer(csvfile_handler, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    \n",
    "    headers = []\n",
    "    headers.extend([f'videoid'])\n",
    "    headers.extend([f'framecount'])\n",
    "    for i in range(33):  # For each of the 33 landmarks\n",
    "        headers.extend([f'Landmark_{i}_X', f'Landmark_{i}_Y', f'Landmark_{i}_Z', f'Landmark_{i}_Visibility'])\n",
    "    landmark_writer.writerow(headers)  \n",
    "    \n",
    "    return csvfile_handler, landmark_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30635fae-3edc-4b21-834b-1880b4535968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:00.680354Z",
     "iopub.status.busy": "2024-06-10T15:50:00.680354Z",
     "iopub.status.idle": "2024-06-10T15:50:00.687190Z",
     "shell.execute_reply": "2024-06-10T15:50:00.687190Z",
     "shell.execute_reply.started": "2024-06-10T15:50:00.680354Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_landmark_row(videoid, frame_count, pose_landmarks):\n",
    "    row = []\n",
    "    row.extend([videoid])\n",
    "    row.extend([frame_count])\n",
    "    \n",
    "    def add_lanmark(index):\n",
    "        landmark = pose_landmarks[0][index]\n",
    "        row.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "\n",
    "    for i in range(33):\n",
    "        add_lanmark(i)\n",
    "    '''\n",
    "    landmark_ids = [0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28]\n",
    "    \n",
    "    for landmark_id in landmark_ids:\n",
    "        add_lanmark(landmark_id)\n",
    "    '''\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceeb049c-503a-4cac-bff0-51f8e51dc0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:00.864599Z",
     "iopub.status.busy": "2024-06-10T15:50:00.863625Z",
     "iopub.status.idle": "2024-06-10T15:50:00.869519Z",
     "shell.execute_reply": "2024-06-10T15:50:00.868535Z",
     "shell.execute_reply.started": "2024-06-10T15:50:00.864599Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw_landmarks(frame, res_pose_landmarks):\n",
    "    for pose_landmarks in res_pose_landmarks:\n",
    "     # Draw the pose landmarks.\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y,\n",
    "                z=landmark.z) for landmark\n",
    "                in pose_landmarks\n",
    "            ])\n",
    "        mp_drawing.draw_landmarks(\n",
    "            frame,\n",
    "            pose_landmarks_proto,\n",
    "            mp_pose.POSE_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae97957f-8ae6-4a04-90ec-ab89fd9fc0a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:01.064179Z",
     "iopub.status.busy": "2024-06-10T15:50:01.063209Z",
     "iopub.status.idle": "2024-06-10T15:50:01.071551Z",
     "shell.execute_reply": "2024-06-10T15:50:01.071551Z",
     "shell.execute_reply.started": "2024-06-10T15:50:01.064179Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_frame(frame, video_width, video_height, bFlip, percentCrop, rotateAngle, bNoise, bBlur):\n",
    "    if bFlip:\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "    if percentCrop != 0:\n",
    "        original_width = video_width\n",
    "        original_height = video_height\n",
    "        crop_width = int(original_width * (1 - percentCrop/100))\n",
    "        crop_height = int(original_height * (1 - percentCrop/100))\n",
    "        x_start = (original_width - crop_width) // 2\n",
    "        y_start = (original_height - crop_height) // 2\n",
    "\n",
    "        frame = frame[y_start:y_start + crop_height, x_start:x_start + crop_width]\n",
    "        frame = cv2.resize(frame, (original_width, original_height))  # Resize back to original dimensions\n",
    "\n",
    "\n",
    "    if rotateAngle != 0:\n",
    "        angle = rotateAngle\n",
    "        (h, w) = frame.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        frame = cv2.warpAffine(frame, M, (w, h))\n",
    "        \n",
    "    if bNoise:\n",
    "        noise = np.zeros(frame.shape, frame.dtype)\n",
    "        cv2.randn(noise, 0, 25)\n",
    "        frame = cv2.add(frame, noise)\n",
    "\n",
    "    if bBlur:\n",
    "        frame = cv2.GaussianBlur(frame, (3, 3), 0) \n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cc08de3-6994-4b03-8cd2-4947eeb83a7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:50:01.339602Z",
     "iopub.status.busy": "2024-06-10T15:50:01.338617Z",
     "iopub.status.idle": "2024-06-10T15:50:01.353471Z",
     "shell.execute_reply": "2024-06-10T15:50:01.353471Z",
     "shell.execute_reply.started": "2024-06-10T15:50:01.339602Z"
    }
   },
   "outputs": [],
   "source": [
    "debug_allowed = True\n",
    "\n",
    "def process_video(row):    \n",
    "    global landmark_fall_writer, landmark_notfall_writer, video_processed_count\n",
    "    \n",
    "    video_filename = row['Filename']\n",
    "    video_path = \"dataset/\" + video_filename\n",
    "\n",
    "    bFlip = int(row['Flip']) \n",
    "    percentCrop = int(row['Crop'])\n",
    "    rotateAngle = int(row['Rotate'])\n",
    "    bNoise = int(row['Noise'])\n",
    "    bBlur = int(row['Blur'])\n",
    "    if bFlip:\n",
    "        video_filename = video_filename + \"_flip\"\n",
    "    if percentCrop != 0:\n",
    "        video_filename = video_filename + \"_crop\" + str(percentCrop)\n",
    "    if rotateAngle != 0:\n",
    "       video_filename = video_filename + \"_rotate\" + str(rotateAngle)\n",
    "    if bNoise:\n",
    "        video_filename = video_filename + \"_noise\"\n",
    "    if bBlur:\n",
    "        video_filename = video_filename + \"_blur\"\n",
    "        \n",
    "    video_filename = video_filename + \"_\" + str(video_processed_count)\n",
    "    \n",
    "    video_begin_frame = int(row['VideoBeginFrame'])\n",
    "    video_end_frame = int(row['VideoEndFrame']) if int(row['VideoEndFrame']) != -1 else get_total_frames(video_path)\n",
    "    fall_begin_frame = int(row['FallBeginFrame'])\n",
    "    fall_end_frame = int(row['FallEndFrame'])\n",
    "    print(\"Reading from video file \", video_path)\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    detector = vision.PoseLandmarker.create_from_options(options)\n",
    "    \n",
    "    good_dataframe = 0\n",
    "    \n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    if fps < 29 or fps > 33:\n",
    "        print(\"Invalid video: FPS != 30 - \", fps)\n",
    "        return\n",
    "\n",
    "    if video_begin_frame == -1:\n",
    "        findex = fall_begin_frame - 120\n",
    "        if findex < 0:\n",
    "            findex = 0\n",
    "            \n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, findex)\n",
    "        frame_count = findex\n",
    "    else:\n",
    "        real_vid_begin_frame = video_begin_frame - 120\n",
    "        if real_vid_begin_frame < 0:\n",
    "            real_vid_begin_frame = 0\n",
    "        \n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, real_vid_begin_frame)\n",
    "        frame_count = real_vid_begin_frame\n",
    "        \n",
    "\n",
    "    last_pos_msec = 0\n",
    "\n",
    "    notfall_blockA_framecount = 0\n",
    "    notfall_blockB_framecount = 0\n",
    "    fall_block_framecount = 0\n",
    "\n",
    "    drop_frame_state = 0\n",
    "\n",
    "\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break  \n",
    "            \n",
    "        #frame = cv2.convertScaleAbs(frame, beta=100)\n",
    "    \n",
    "        video_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        video_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))   \n",
    "        frame = process_frame(frame, video_width, video_height, bFlip, percentCrop, rotateAngle, bNoise, bBlur)\n",
    "        \n",
    "            \n",
    "        rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "\n",
    "        if last_pos_msec > video.get(cv2.CAP_PROP_POS_MSEC):\n",
    "            break\n",
    "            \n",
    "        last_pos_msec = int(video.get(cv2.CAP_PROP_POS_MSEC))\n",
    "        results = detector.detect_for_video(mp_image, last_pos_msec)\n",
    "        if results.pose_landmarks:\n",
    "            if drop_frame_state == 2:\n",
    "                pass\n",
    "                #print(\"Dropped frame detected. Exiting loop\")\n",
    "                #break\n",
    "                \n",
    "            drop_frame_state = 1\n",
    "            \n",
    "            good_dataframe += 1\n",
    "            collecting_data = False\n",
    "            \n",
    "            if fall_begin_frame != -1 and fall_end_frame != -1:\n",
    "             \tif frame_count in range(fall_begin_frame, fall_end_frame):\n",
    "                    row = build_landmark_row(video_filename, frame_count, results.pose_landmarks)\n",
    "                    landmark_fall_writer.writerow(row)\n",
    "                    fall_block_framecount += 1\n",
    "                    collecting_data = True\n",
    "            if video_begin_frame != -1:\n",
    "                end_zone = fall_begin_frame - 1\n",
    "                if fall_begin_frame == -1:\n",
    "                    end_zone = video_end_frame\n",
    "                if frame_count in range(video_begin_frame, end_zone):\n",
    "                    row = build_landmark_row(video_filename + \"_b1\", frame_count, results.pose_landmarks)\n",
    "                    landmark_notfall_writer.writerow(row)\n",
    "                    notfall_blockA_framecount += 1\n",
    "                    collecting_data = True\n",
    "                if fall_end_frame != -1:\n",
    "                    if frame_count in range(fall_end_frame+1, video_end_frame):\n",
    "                        row = build_landmark_row(video_filename + \"_b2\", frame_count, results.pose_landmarks)\n",
    "                        landmark_notfall_writer.writerow(row)          \n",
    "                        notfall_blockB_framecount += 1\n",
    "                        collecting_data = True\n",
    "            if debug_allowed and collecting_data:\n",
    "                frame = draw_landmarks(frame, results.pose_landmarks)\n",
    "        else:\n",
    "            if drop_frame_state == 1:\n",
    "                drop_frame_state = 2\n",
    "            \n",
    "        frame_count += 1      \n",
    "        if (video_begin_frame == -1 and frame_count >= fall_end_frame) or (frame_count >= video_end_frame):\n",
    "            break\n",
    "\n",
    "        if debug_allowed:      \n",
    "            cv2.imshow(\"Image\", frame)\n",
    "            if cv2.waitKey(1) == ord('q'):\n",
    "               break\n",
    "            \n",
    "    #if good_dataframe > 0:\n",
    "    #    print(\"good_dataframe:\", good_dataframe)\n",
    "        \n",
    "    print(\"video =\", video_filename, \"fall_block_framecount =\", fall_block_framecount, \", notfall_blockA_framecount =\", notfall_blockA_framecount, \"notfall_blockB_framecount =\", notfall_blockB_framecount)\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecc1e647-e873-42cf-876a-39dc4913c1e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:48:53.338331Z",
     "iopub.status.busy": "2024-06-10T15:48:53.337355Z",
     "iopub.status.idle": "2024-06-10T15:49:01.551293Z",
     "shell.execute_reply": "2024-06-10T15:49:01.551293Z",
     "shell.execute_reply.started": "2024-06-10T15:48:53.338331Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_noise_15 fall_block_framecount = 0 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_3 fall_block_framecount = 38 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_blur_18 fall_block_framecount = 46 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_flip_6 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_crop10_9 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_rotate10_12 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "video_processed_count = 0\n",
    "# Assuming your prepare_csv_file and process_video functions are defined elsewhere\n",
    "'''\n",
    "fall_csvfile, landmark_fall_writer = prepare_csv_file('dataset/may/train/FALL.csv')\n",
    "notfall_csvfile, landmark_notfall_writer = prepare_csv_file('dataset/may/train/NOT_FALL.csv')\n",
    "csv_label_file_path = \"dataset/may/train/augmented_data.csv\"\n",
    "'''\n",
    "'''\n",
    "fall_csvfile, landmark_fall_writer = prepare_csv_file('dataset/may/val/FALL.csv')\n",
    "notfall_csvfile, landmark_notfall_writer = prepare_csv_file('dataset/may/val/NOT_FALL.csv')\n",
    "csv_label_file_path = \"dataset/may/val/augmented_data.csv\"\n",
    "'''\n",
    "'''\n",
    "fall_csvfile, landmark_fall_writer = prepare_csv_file('dataset/may/test/FALL.csv')\n",
    "notfall_csvfile, landmark_notfall_writer = prepare_csv_file('dataset/may/test/NOT_FALL.csv')\n",
    "csv_label_file_path = \"dataset/may/test/augmented_data.csv\"\n",
    "'''\n",
    "fall_csvfile, landmark_fall_writer = prepare_csv_file('dataset/pi_test_set/FALL.csv')\n",
    "notfall_csvfile, landmark_notfall_writer = prepare_csv_file('dataset/pi_test_set/NOT_FALL.csv')\n",
    "csv_label_file_path = \"dataset/pi_test_set/data2.csv\"\n",
    "\n",
    "# Function wrapper to handle both regular and flipped processing\n",
    "def process_video_wrapper(row):\n",
    "    global video_processed_count\n",
    "    video_processed_count += 3;\n",
    "    process_video(row)\n",
    "\n",
    "\n",
    "# Load all rows into memory; ensure your dataset can fit into RAM\n",
    "all_rows = []\n",
    "with open(csv_label_file_path, mode='r', newline='') as file:\n",
    "    csv_dataset_label = csv.DictReader(file)\n",
    "    all_rows = [row for row in csv_dataset_label]\n",
    "\n",
    "# Use ThreadPoolExecutor to process videos in parallel\n",
    "with ThreadPoolExecutor(max_workers=40) as executor:\n",
    "    # Create future tasks for both regular and flipped processing for each video\n",
    "    futures = [executor.submit(process_video_wrapper, row) for row in all_rows]\n",
    "    \n",
    "    # Wait for all futures to complete, you can also handle results or exceptions here\n",
    "    for future in as_completed(futures):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            # Optionally handle result or increment counter\n",
    "            video_processed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "fall_csvfile.close()\n",
    "notfall_csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff844908-76d4-432c-ac8b-17f0b9cbf9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-10T15:52:52.217541Z",
     "iopub.status.busy": "2024-06-10T15:52:52.216564Z",
     "iopub.status.idle": "2024-06-10T15:53:19.344631Z",
     "shell.execute_reply": "2024-06-10T15:53:19.344631Z",
     "shell.execute_reply.started": "2024-06-10T15:52:52.217541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_0 fall_block_framecount = 38 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_flip_0 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_crop10_0 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_rotate10_0 fall_block_framecount = 47 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_noise_0 fall_block_framecount = 36 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n",
      "Reading from video file  dataset/videos\\Le2i\\Office\\video (11).out.avi\n",
      "video = videos\\Le2i\\Office\\video (11).out.avi_blur_0 fall_block_framecount = 46 , notfall_blockA_framecount = 0 notfall_blockB_framecount = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fall_csvfile, landmark_fall_writer = prepare_csv_file('dataset/pi_test_set/FALL.csv')\n",
    "notfall_csvfile, landmark_notfall_writer = prepare_csv_file('dataset/pi_test_set/NOT_FALL.csv')\n",
    "csv_label_file_path = \"dataset/pi_test_set/data2.csv\"\n",
    "\n",
    "video_processed_count = 0\n",
    "with open(csv_label_file_path, mode='r', newline='') as file:\n",
    "    csv_dataset_label = csv.DictReader(file)\n",
    "    for row in csv_dataset_label:\n",
    "        process_video(row)\n",
    "    \n",
    "fall_csvfile.close()\n",
    "notfall_csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "236de323-9edf-4eda-a80a-eade09960c03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-06T07:52:36.415921Z",
     "iopub.status.busy": "2024-06-06T07:52:36.415921Z",
     "iopub.status.idle": "2024-06-06T07:52:36.420804Z",
     "shell.execute_reply": "2024-06-06T07:52:36.420804Z",
     "shell.execute_reply.started": "2024-06-06T07:52:36.415921Z"
    }
   },
   "outputs": [],
   "source": [
    "fall_csvfile.close()\n",
    "notfall_csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fab228-11f5-4878-8a31-93318bb7de88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
